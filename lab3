import matplotlib.pyplot as plt
import random as rnd
import numpy as np
from matplotlib.widgets import Slider

# Константы
N = 15  # Количество базовых точек
ALPHA = 0.0001  # Скорость обучения
NOISE_RANGE = 6  # Разброс шума

# Генерация данных
x = np.linspace(1, N, N*2)  # Начинаем с 1, чтобы избежать log(0)
y_real = 2 * (x ** 2) + 5  # Исходная функция y = 2x² + 5
y = y_real + np.random.uniform(-NOISE_RANGE, NOISE_RANGE, len(x))  # Зашумленные данные

# Создание фигуры
fig, ax = plt.subplots(figsize=(10, 6))
plt.subplots_adjust(bottom=0.25)
ax.plot(x, y_real, 'g-', label='Исходная функция')
scatter = ax.scatter(x, y, c='b', label='Зашумленные данные')
line, = ax.plot(x, y_real, 'r-', label='Аппроксимация')
ax.legend()
ax.grid(True)

# Функция градиентного спуска
def gradient_descent(x, y, a_start, b_start, c_start, alpha, iterations):
    a, b, c = a_start, b_start, c_start
    n = len(x)
    
    for _ in range(iterations):
        # Предсказание
        y_pred = a * (x ** b) + c
        
        # Градиенты
        grad_a = (2/n) * np.sum((y_pred - y) * (x ** b))
        grad_b = (2/n) * np.sum((y_pred - y) * a * (x ** b) * np.log(x))
        grad_c = (2/n) * np.sum(y_pred - y)
        
        # Обновление параметров
        a -= alpha * grad_a
        b -= alpha * grad_b * 0.01  # Меньший шаг для b
        c -= alpha * grad_c
        
    return a * (x ** b) + c

# Слайдер
ax_iter = plt.axes([0.25, 0.1, 0.65, 0.03])
iter_slider = Slider(ax_iter, 'Итерации', 0, 1000, valinit=0, valstep=1)

# Обновление графика
def update(val):
    iterations = int(iter_slider.val)
    y_pred = gradient_descent(x, y, 1, 1, 1, ALPHA, iterations)
    line.set_ydata(y_pred)
    fig.canvas.draw_idle()

iter_slider.on_changed(update)
update(0)  # Инициализация

plt.show()
